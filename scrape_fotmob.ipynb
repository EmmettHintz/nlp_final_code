{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Fotmob using Selenium\n",
    "Work done by James"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import necessary modules\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Function to initialize Selenium WebDriver\n",
    "def initialize_driver():\n",
    "    # Set up Chrome options for better performance and to prevent popups\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Run in headless mode to avoid UI\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    # Specify the path to your own ChromeDriver\n",
    "    chromedriver_path = os.path.expanduser(\"/Users/jamesngugi/Downloads/chromedriver-mac-arm64/chromedriver\")\n",
    "    # Initialize the driver with the specified ChromeDriver\n",
    "    driver = webdriver.Chrome(service=Service(chromedriver_path), options=options)\n",
    "    return driver\n",
    "\n",
    "# Function to extract links from a specific URL\n",
    "def extract_links(url):\n",
    "    driver = initialize_driver()\n",
    "    try:\n",
    "        # Open the given URL\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # Give some time for the page to load\n",
    "        \n",
    "        # Extract links only from the specified div with class \"slick-slide slick-active slick-current\"\n",
    "        div_elements = driver.find_elements(By.CLASS_NAME, 'slick-slide.slick-active.slick-current')\n",
    "        links = []\n",
    "        for div in div_elements:\n",
    "            anchor_tags = div.find_elements(By.TAG_NAME, 'a')\n",
    "            links.extend([anchor.get_attribute('href') for anchor in anchor_tags if anchor.get_attribute('href')])\n",
    "        \n",
    "    finally:\n",
    "        # Quit the driver once done\n",
    "        driver.quit()\n",
    "    return links\n",
    "\n",
    "# Function to extract links from multiple URLs\n",
    "def extract_links_from_urls(urls):\n",
    "    all_links = []\n",
    "    for url in urls:\n",
    "        print(f\"Extracting links from: {url}\")\n",
    "        links = extract_links(url)\n",
    "        all_links.extend(links)\n",
    "    return all_links\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.fotmob.com/leagues/47/matches/premier-league?season=2023-2024&group=by-round&round=\"\n",
    "    urls = [f\"{base_url}{i}\" for i in range(1, 39)]\n",
    "    \n",
    "    links_list = extract_links_from_urls(urls)\n",
    "    \n",
    "\n",
    "# Ensure to run `pip install selenium` before running this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are going to remove one game that was abandoned because a player collapsed and keep the replayed game of the same exact match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_list.remove(\"https://www.fotmob.com/matches/luton-town-vs-afc-bournemouth/2ea97q#4193691\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scraping to get the actual commentary\n",
    "\n",
    "Now we scrape to get the actual commentary. We use all of the links in the list: \"links_list\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import time  # For adding delays if necessary\n",
    "import pandas as pd  # For creating the DataFrame\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re  # For extracting quoted text from divs\n",
    "\n",
    "# Configure logging to display INFO and higher-level messages\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# List of URLs to process\n",
    "urls = links_list  # Ensure this list is defined with your target URLs\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration (Windows)\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model (Linux)\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")  # Ensure content is fully loaded in headless mode\n",
    "\n",
    "# Add arguments to make headless mode less detectable\n",
    "chrome_options.add_argument(\"start-maximized\")\n",
    "chrome_options.add_argument(\"disable-infobars\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "\n",
    "# Suppress unnecessary logging from Selenium\n",
    "chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "# Path to the Chromedriver executable\n",
    "webdriver_service = Service('/Users/jamesngugi/Downloads/chromedriver-mac-arm64/chromedriver')  # Update as needed\n",
    "\n",
    "# Initialize the WebDriver with exception handling\n",
    "try:\n",
    "    driver = webdriver.Chrome(service=webdriver_service, options=chrome_options)\n",
    "    logging.info(\"WebDriver initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing WebDriver: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Function to process each URL\n",
    "def process_url(url):\n",
    "    logging.info(f\"Processing URL: {url}\")\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        logging.info(f\"Page loaded: {url}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading URL {url}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Extract the title to determine the home and away teams\n",
    "    try:\n",
    "        title_element = driver.find_element(By.TAG_NAME, 'title')\n",
    "        title_text = title_element.get_attribute('innerText')\n",
    "        logging.info(f\"Extracted title: {title_text}\")\n",
    "        \n",
    "        # Extract home and away teams based on title format\n",
    "        title_main_part = title_text.split(\" - \")[0]  # Adjust based on actual title format\n",
    "        home_team, away_team = title_main_part.split(\" vs \")\n",
    "        logging.info(f\"Home team: {home_team}, Away team: {away_team}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting title or parsing teams from {url}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Initialize WebDriverWait\n",
    "    wait = WebDriverWait(driver, 10)  # Wait up to 10 seconds for elements to appear\n",
    "\n",
    "    # Interact with the toggle button\n",
    "    try:\n",
    "        toggle_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'css-19d3bb6-Toggle')))\n",
    "        if toggle_button.get_attribute(\"aria-checked\") == \"true\":\n",
    "            toggle_button.click()\n",
    "            logging.info(f\"Clicked toggle button to set to false on {url}\")\n",
    "        else:\n",
    "            logging.info(f\"Toggle button already set to false on {url}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error interacting with toggle button on {url}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Wait for the content to load after toggling\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'css-1wqh8j4-LiveTickerTextOnly')))\n",
    "        logging.info(f\"Content loaded after toggling on {url}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error waiting for content on {url}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Extract text from all relevant elements in the order they appear\n",
    "    try:\n",
    "        # Use XPath to select all relevant divs and p elements in the order they appear\n",
    "        ticker_elements = driver.find_elements(By.XPATH, \"\"\"\n",
    "            //div[contains(@class, 'LiveTickerTextOnly') or contains(@class, 'LiveTickerItemContent')]\n",
    "            | //p[contains(@class, 'LiveTickerTextOnly')]\n",
    "        \"\"\")\n",
    "\n",
    "        extracted_texts = []\n",
    "        for elem in ticker_elements:\n",
    "            classes = elem.get_attribute('class')\n",
    "            if 'css-ttt5nx-LiveTickerItemContent' in classes:\n",
    "                # Extract text excluding nested <span> elements\n",
    "                text = driver.execute_script(\"\"\"\n",
    "                    var element = arguments[0];\n",
    "                    var text = '';\n",
    "                    for (var i = 0; i < element.childNodes.length; i++) {\n",
    "                        if (element.childNodes[i].nodeType === Node.TEXT_NODE) {\n",
    "                            text += element.childNodes[i].textContent.trim() + ' ';\n",
    "                        }\n",
    "                    }\n",
    "                    return text.trim();\n",
    "                \"\"\", elem)\n",
    "                if text:\n",
    "                    extracted_texts.append(text)\n",
    "            else:\n",
    "                # For other classes, extract the full text\n",
    "                text = elem.text.strip()\n",
    "                if text:\n",
    "                    extracted_texts.append(text)\n",
    "\n",
    "        # Reverse the list to have the latest texts first\n",
    "        concatenated_text = ' '.join(reversed(extracted_texts))\n",
    "        logging.info(f\"Extracted text from {url}\")\n",
    "        return home_team, away_team, concatenated_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text on {url}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# List to store data for DataFrame\n",
    "data = []\n",
    "\n",
    "# Process each URL\n",
    "for url in urls:\n",
    "    home_team, away_team, text = process_url(url)\n",
    "    if home_team and away_team and text:\n",
    "        data.append({'home': home_team, 'away': away_team, 'url': url, 'commentary': text})\n",
    "    else:\n",
    "        logging.warning(f\"No valid data extracted from {url}\")\n",
    "\n",
    "    # Optional: Sleep for a short duration to be polite to the server\n",
    "    # time.sleep(1)  # Sleep for 1 second\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "logging.info(\"WebDriver closed.\")\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=['home', 'away', 'url', 'commentary'])\n",
    "\n",
    "# Add an indexing column 'game'\n",
    "df.insert(0, 'game', range(1, len(df) + 1))\n",
    "\n",
    "# Output the DataFrame\n",
    "print(df.to_string())\n",
    "logging.info(\"DataFrame created and printed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
